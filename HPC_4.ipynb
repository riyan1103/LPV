{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWO7f0pvSvQ7",
        "outputId": "a045f54d-a059-496a-d988-a9751fa202b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing HPC-4.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile HPC-4.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "__global__\n",
        "void add(int* A, int* B, int* C, int size) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        C[tid] = A[tid] + B[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void multiply(int* A, int* B, int* C, int size) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < size && col < size) {\n",
        "        int sum = 0;\n",
        "        for (int i = 0; i < size; i++) {\n",
        "            sum += A[row * size + i] * B[i * size + col];\n",
        "        }\n",
        "        C[row * size + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void initializeVector(int* vector, int size) {\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        vector[i] = rand() % 10;\n",
        "    }\n",
        "}\n",
        "\n",
        "void initializeMatrix(int* matrix, int size) {\n",
        "    for (int i = 0; i < size * size; i++) {\n",
        "        matrix[i] = rand() % 10;\n",
        "    }\n",
        "}\n",
        "\n",
        "void printVector(int* vector, int size) {\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        printf(\"%d \", vector[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "}\n",
        "\n",
        "void printMatrix(int* matrix, int size) {\n",
        "    for (int row = 0; row < size; row++) {\n",
        "        for (int col = 0; col < size; col++) {\n",
        "            printf(\"%d \", matrix[row * size + col]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 4;\n",
        "\n",
        "    int* A, * B, * C;\n",
        "    int vectorSize = N;\n",
        "    size_t vectorBytes = vectorSize * sizeof(int);\n",
        "\n",
        "    A = (int*)malloc(vectorBytes);\n",
        "    B = (int*)malloc(vectorBytes);\n",
        "    C = (int*)malloc(vectorBytes);\n",
        "\n",
        "    initializeVector(A, vectorSize);\n",
        "    initializeVector(B, vectorSize);\n",
        "\n",
        "    printf(\"Vector A: \");\n",
        "    printVector(A, N);\n",
        "    printf(\"Vector B: \");\n",
        "    printVector(B, N);\n",
        "\n",
        "    int* X, * Y, * Z;\n",
        "    cudaMalloc(&X, vectorBytes);\n",
        "    cudaMalloc(&Y, vectorBytes);\n",
        "    cudaMalloc(&Z, vectorBytes);\n",
        "\n",
        "    cudaMemcpy(X, A, vectorBytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(Y, B, vectorBytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlockVec = 256;\n",
        "    int blocksPerGridVec = (N + threadsPerBlockVec - 1) / threadsPerBlockVec;\n",
        "\n",
        "    add<<<blocksPerGridVec, threadsPerBlockVec>>>(X, Y, Z, N);\n",
        "\n",
        "    // Check for errors after the kernel call\n",
        "    cudaError_t error = cudaGetLastError();\n",
        "    if (error != cudaSuccess) {\n",
        "        printf(\"CUDA error in addition kernel: %s\\n\", cudaGetErrorString(error));\n",
        "    }\n",
        "    cudaDeviceSynchronize();  // Ensure the kernel has finished executing\n",
        "\n",
        "    cudaMemcpy(C, Z, vectorBytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Addition: \");\n",
        "    printVector(C, N);\n",
        "\n",
        "    free(A);\n",
        "    free(B);\n",
        "    free(C);\n",
        "\n",
        "    cudaFree(X);\n",
        "    cudaFree(Y);\n",
        "    cudaFree(Z);\n",
        "\n",
        "    // Matrix multiplication\n",
        "    int* D, * E, * F;\n",
        "    int matrixSize = N;\n",
        "    size_t matrixBytes = matrixSize * matrixSize * sizeof(int);\n",
        "\n",
        "    D = (int*)malloc(matrixBytes);\n",
        "    E = (int*)malloc(matrixBytes);\n",
        "    F = (int*)malloc(matrixBytes);\n",
        "\n",
        "    initializeMatrix(D, matrixSize);\n",
        "    initializeMatrix(E, matrixSize);\n",
        "\n",
        "    printf(\"\\nMatrix D: \\n\");\n",
        "    printMatrix(D, matrixSize);\n",
        "\n",
        "    printf(\"Matrix E: \\n\");\n",
        "    printMatrix(E, matrixSize);\n",
        "\n",
        "    int* M, * NMat, * O;\n",
        "    cudaMalloc(&M, matrixBytes);\n",
        "    cudaMalloc(&NMat, matrixBytes);\n",
        "    cudaMalloc(&O, matrixBytes);\n",
        "\n",
        "    cudaMemcpy(M, D, matrixBytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(NMat, E, matrixBytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Use 16x16 thread blocks for better performance\n",
        "    int threadsPerBlockMat = 16;\n",
        "    dim3 threadsMat(threadsPerBlockMat, threadsPerBlockMat);\n",
        "    dim3 blocksMat((matrixSize + threadsPerBlockMat - 1) / threadsPerBlockMat, (matrixSize + threadsPerBlockMat - 1) / threadsPerBlockMat);\n",
        "\n",
        "    multiply<<<blocksMat, threadsMat>>>(M, NMat, O, matrixSize);\n",
        "\n",
        "    // Check for errors after the kernel call\n",
        "    error = cudaGetLastError();\n",
        "    if (error != cudaSuccess) {\n",
        "        printf(\"CUDA error in multiplication kernel: %s\\n\", cudaGetErrorString(error));\n",
        "    }\n",
        "    cudaDeviceSynchronize();  // Ensure the kernel has finished executing\n",
        "\n",
        "    cudaMemcpy(F, O, matrixBytes, cudaMemcpyDeviceToHost);\n",
        "    printf(\"Multiplication: \\n\");\n",
        "    printMatrix(F, matrixSize);\n",
        "\n",
        "    free(D);\n",
        "    free(E);\n",
        "    free(F);\n",
        "\n",
        "    cudaFree(M);\n",
        "    cudaFree(NMat);\n",
        "    cudaFree(O);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure to remove the CUDA symlink if needed\n",
        "!rm -rf /usr/local/cuda\n",
        "!ln -s /usr/local/cuda-12.5 /usr/local/cuda  # Replace with your CUDA version if necessary\n",
        "\n",
        "# Compile the CUDA code with the correct architecture for Tesla P4 (sm_61)\n",
        "!nvcc -arch=sm_75 HPC-4.cu -o HPC-4\n"
      ],
      "metadata": {
        "id": "81PZ5K3wTO3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.geteuid() == 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLgNcXO_UJJx",
        "outputId": "ea24f9a2-cc0d-45b5-c8b3-fa0433ffc825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find / -name \"nvcc\" 2>/dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_owyEJtmU9X8",
        "outputId": "517a0d2f-dc34-47e9-cdca-1751a287a3d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/cuda-12.5/bin/nvcc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./HPC-4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CeesvMkU-fW",
        "outputId": "55d7c3d4-aec0-498b-ec5c-432ccce69250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector A: 3 1 2 0 \n",
            "Vector B: 3 0 1 2 \n",
            "Addition: 6 1 3 2 \n",
            "\n",
            "Matrix D: \n",
            "9 1 2 7 \n",
            "0 9 3 6 \n",
            "0 6 2 6 \n",
            "1 8 7 9 \n",
            "\n",
            "Matrix E: \n",
            "2 0 2 3 \n",
            "7 5 9 2 \n",
            "2 8 9 7 \n",
            "3 6 1 2 \n",
            "\n",
            "Multiplication: \n",
            "50 63 52 57 \n",
            "87 105 114 51 \n",
            "64 82 78 38 \n",
            "99 150 146 86 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY1sci2lVgjy",
        "outputId": "e06fd04d-04a1-4669-c0e5-2736bc031592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --query-gpu=compute_cap --format=csv,noheader"
      ],
      "metadata": {
        "id": "UXUlbKEAaxvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "321200c7-67c0-442b-bb96-e40fbd922081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.5\n"
          ]
        }
      ]
    }
  ]
}